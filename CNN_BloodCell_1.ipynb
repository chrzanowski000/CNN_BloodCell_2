{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "bbyayKmx5UkU",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Whole notebook has been run on Google colab pro,\n",
        "\n",
        "created by: Michał Chrzanowski 2022\n",
        "\n",
        "important note, if model stucks around 25% accuracy restart whole model and calculate again"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ETIz7k-CqFE0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#modules not used in this notebook but may come in handy later\n",
        "\n",
        "# image processing of images\n",
        "from skimage.color import rgb2hsv, hsv2rgb\n",
        "def color_isolate(img):\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    img_hsv = rgb2hsv(img[:,:,:3])   \n",
        "    #MASK\n",
        "    mask_1 = img_hsv [:,:,0] > 200/360\n",
        "    mask_2 = img_hsv [:,:,0] < 280/360\n",
        "    saturation_1 = img_hsv [:,:,1] > 0.35\n",
        "    saturation_2 = img_hsv [:,:,1] < 0.70\n",
        "    \n",
        "    mask= mask_1*mask_1*saturation_1*saturation_2\n",
        "\n",
        "    image_filtered = np.dstack((img[:,:,0]*mask,\n",
        "                                img[:,:,1]*mask,\n",
        "                                img[:,:,2]*mask))\n",
        "\n",
        "    return image_filtered\n",
        "\n",
        "#used to preview images loaded in model\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()[0]\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)), interpolation='nearest')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTucYHtcAzU6",
        "outputId": "35553a2c-0d8e-49db-e6a2-6ca1a8038775",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No LSB modules are available.\n",
            "Distributor ID:\tUbuntu\n",
            "Description:\tUbuntu 18.04.6 LTS\n",
            "Release:\t18.04\n",
            "Codename:\tbionic\n",
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.126\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4000.25\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 85\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "stepping\t: 3\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2000.126\n",
            "cache size\t: 39424 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm mpx avx512f avx512dq rdseed adx smap clflushopt clwb avx512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsaves arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa mmio_stale_data retbleed\n",
            "bogomips\t: 4000.25\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         167G   39G  129G  23% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G   40K  5.7G   1% /dev/shm\n",
            "/dev/root       2.0G  1.1G  910M  54% /sbin/docker-init\n",
            "tmpfs           6.4G   40K  6.4G   1% /var/colab\n",
            "/dev/sda1       174G   40G  134G  23% /opt/bin/.nvidia\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n",
            "drive            15G  2.9G   13G  19% /content/drive\n",
            "MemTotal:       13297228 kB\n",
            "MemFree:         4615372 kB\n",
            "MemAvailable:    9664084 kB\n",
            "Buffers:          182932 kB\n",
            "Cached:          3990228 kB\n",
            "SwapCached:            0 kB\n",
            "Active:          1953052 kB\n",
            "Inactive:        6091196 kB\n",
            "Active(anon):        980 kB\n",
            "Inactive(anon):  2988796 kB\n",
            "Active(file):    1952072 kB\n",
            "Inactive(file):  3102400 kB\n",
            "Unevictable:           0 kB\n",
            "Mlocked:               0 kB\n",
            "SwapTotal:             0 kB\n",
            "SwapFree:              0 kB\n",
            "Dirty:              1040 kB\n",
            "Writeback:             0 kB\n",
            "AnonPages:       3871024 kB\n",
            "Mapped:          1170480 kB\n",
            "Shmem:            179504 kB\n",
            "KReclaimable:     320164 kB\n",
            "Slab:             397204 kB\n",
            "SReclaimable:     320164 kB\n",
            "SUnreclaim:        77040 kB\n",
            "KernelStack:       22320 kB\n",
            "PageTables:        29080 kB\n",
            "NFS_Unstable:          0 kB\n",
            "Bounce:                0 kB\n",
            "WritebackTmp:          0 kB\n",
            "CommitLimit:     6648612 kB\n",
            "Committed_AS:    7675900 kB\n",
            "VmallocTotal:   34359738367 kB\n",
            "VmallocUsed:       70892 kB\n",
            "VmallocChunk:          0 kB\n",
            "Percpu:             1416 kB\n",
            "HardwareCorrupted:     0 kB\n",
            "AnonHugePages:         0 kB\n",
            "ShmemHugePages:        0 kB\n",
            "ShmemPmdMapped:        0 kB\n",
            "FileHugePages:         0 kB\n",
            "FilePmdMapped:         0 kB\n",
            "CmaTotal:              0 kB\n",
            "CmaFree:               0 kB\n",
            "HugePages_Total:       0\n",
            "HugePages_Free:        0\n",
            "HugePages_Rsvd:        0\n",
            "HugePages_Surp:        0\n",
            "Hugepagesize:       2048 kB\n",
            "Hugetlb:               0 kB\n",
            "DirectMap4k:      453440 kB\n",
            "DirectMap2M:    13174784 kB\n",
            "DirectMap1G:     2097152 kB\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "speedtest-cli is already the newest version (2.0.0-1ubuntu1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 20 not upgraded.\n",
            "Retrieving speedtest.net configuration...\n",
            "Cannot retrieve speedtest configuration\n",
            "ERROR: HTTP Error 403: Forbidden\n"
          ]
        }
      ],
      "source": [
        "!lsb_release -a #Linux info\n",
        "!cat /proc/cpuinfo # CPU info\n",
        "!df -h #disc info\n",
        "!cat /proc/meminfo #RAM info\n",
        "!sudo apt install speedtest-cli #library for speedtesting\n",
        "!speedtest-cli # network speed test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZkAHGr3iBN8t",
        "outputId": "efc3590c-0023-4cfa-940c-45feaff69ba1",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Oct 23 15:28:42 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 510.73.05    Driver Version: 510.73.05    CUDA Version: 11.6     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA RTX A4000    Off  | 00000000:00:05.0 Off |                  Off |\n",
            "| 41%   48C    P8    17W / 140W |      0MiB / 16376MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi #GPU info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0x0-BEFBYx8",
        "outputId": "a52bc908-3d89-4e21-b39f-63c33d700ce6",
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.13.4-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.10.1-py2.py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.6/166.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (5.9.1)\n",
            "Collecting promise<3,>=2.0\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.1.27)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (2.28.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from wandb) (5.4.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/lib/python3/dist-packages (from wandb) (1.14.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.0,<5,>=3.12.0 in /usr/local/lib/python3.9/dist-packages (from wandb) (3.19.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb) (63.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2019.11.28)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (2.1.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.10)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3,>=2.0.0->wandb) (2.8)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.4/140.4 kB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
            "Building wheels for collected packages: promise, pathtools\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21486 sha256=1757d5dde3687902747b57f2122e818bbccd0b7100b9d37592fbf2f627afe038\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/e8/83/ddea66100678d139b14bc87692ece57c6a2a937956d2532608\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=a03b9b3479d8411a25c84ddc88d623b2b411b2f0d96334a30fa35e140a8f6454\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0a/67/ada2a22079218c75a88361c0782855cc72aebc4d18d0289d05\n",
            "Successfully built promise pathtools\n",
            "Installing collected packages: pathtools, urllib3, shortuuid, setproctitle, promise, docker-pycreds, sentry-sdk, wandb\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.10\n",
            "    Uninstalling urllib3-1.26.10:\n",
            "      Successfully uninstalled urllib3-1.26.10\n",
            "Successfully installed docker-pycreds-0.4.0 pathtools-0.1.2 promise-2.3 sentry-sdk-1.10.1 setproctitle-1.3.2 shortuuid-1.0.9 urllib3-1.26.12 wandb-0.13.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ],
      "source": [
        "# I decided to use external plotting service Weights and biases. It provides easy live preview of model state and  allows convenient runs comparasion\n",
        "!pip install wandb\n",
        "!wandb login 33cccacf373072ab6a5edc82d4770dddf40d42fb\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGTvVH2x63y2",
        "outputId": "2e1cb934-7c9c-4ba8-aa29-a07291d6a96f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "allocated CUDA memory:  0\n",
            "cached CUDA memory:  0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/memory.py:391: FutureWarning: torch.cuda.memory_cached has been renamed to torch.cuda.memory_reserved\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import time\n",
        "import torch\n",
        "import torchvision  # torch package for vision related things\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.transforms as transforms  # Transformations and augmentations\n",
        "from torch import optim  # For optimizers\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import DataLoader #Dataloader module\n",
        "from torch.utils.data import Dataset # Dataset module\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm #nice progress bar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from skimage.io import imshow, imread\n",
        "\n",
        "# Libraries for dataloader\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from PIL import Image\n",
        "import cv2\n",
        "#Checking whether GPU RAM is empty\n",
        "print('allocated CUDA memory: ',torch.cuda.memory_allocated())\n",
        "print('cached CUDA memory: ',torch.cuda.memory_cached())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#hyperparameters\n",
        "root = '/notebooks/dataset2-master/dataset2-master/images'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import os,time\n",
        "import cv2\n",
        "\n",
        "#img_dir='/notebooks/DATA'\n",
        "def verify_folder(folder_dir):\n",
        "    \n",
        "    def verify_image(img_file):\n",
        "         #test image\n",
        "         try:\n",
        "            v_image = Image.open(img_file)\n",
        "            v_image.verify()\n",
        "            return True;\n",
        "            #is valid\n",
        "            #print(\"valid file: \"+img_file)\n",
        "         except OSError:\n",
        "            return False;\n",
        "\n",
        "    for root, dirs, files in os.walk(folder_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".jpg\") or file.endswith(\".jpeg\") or file.endswith(\".png\"):\n",
        "                currentFile=os.path.join(root, file)\n",
        "                #print(currentFile)\n",
        "                #test image\n",
        "                if verify_image(currentFile):\n",
        "                    im = cv2.imread(currentFile)\n",
        "                    if im.shape[0] < 64 or im.shape[1] < 64:\n",
        "                        print('undersized file')\n",
        "                        os.remove(currentFile)\n",
        "                else:\n",
        "                    os.remove(currentFile)\n",
        "                    print(\"corrupt file\")\n",
        "                    \n",
        "            else:\n",
        "                os.remove(os.path.join(root, file))\n",
        "                print(\"unsupported file extension\")\n",
        "    print('DONE')\n",
        "                    \n",
        "verify_folder('/notebooks/dataset2-master/dataset2-master/images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MEoHkZFK7f_b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# DATALOADERS\n",
        "\n",
        "# Train Loader\n",
        "class BloodCell_train(Dataset):\n",
        "    def __init__(self, root ,transform):\n",
        "        self.labels = []\n",
        "        self.dirName_1 = os.join(root,'/TRAIN/EOSINOPHIL') # path to training data with EOSINOPHILS cells\n",
        "        self.dirName_2 = os.join(root,'/TRAIN/LYMPHOCYTE') # path to training data with LYMPHOCYTES cells\n",
        "        self.dirName_3 = os.join(root,'/TRAIN/MONOCYTE') # path to training data with MONOCYTES cells\n",
        "        self.dirName_4 = os.join(root,'/TRAIN/NEUTROPHIL') # path to training data with NEUTROPHILS cells\n",
        "        self.files_names = []\n",
        "        self.transform = transform\n",
        "        self.load_images()\n",
        "    \n",
        "\n",
        "    def load_images(self):\n",
        "\n",
        "        # create list of paths to images\n",
        "        files_1 = [join(self.dirName_1, f) for f in listdir(self.dirName_1) if isfile(join(self.dirName_1, f))]\n",
        "        files_2 = [join(self.dirName_2, f) for f in listdir(self.dirName_2) if isfile(join(self.dirName_2, f))]\n",
        "        files_3 = [join(self.dirName_3, f) for f in listdir(self.dirName_3) if isfile(join(self.dirName_3, f))]\n",
        "        files_4 = [join(self.dirName_4, f) for f in listdir(self.dirName_4) if isfile(join(self.dirName_4, f))]\n",
        "        \n",
        "\n",
        "        # connect lists of different cells in one big list\n",
        "        self.files_names = files_1 + files_2 + files_3 + files_4\n",
        "\n",
        "        # creating label list\n",
        "        for file_name in tqdm(files_1):\n",
        "            self.labels.append(0)\n",
        "\n",
        "        for file_name in tqdm(files_2):\n",
        "            self.labels.append(1)\n",
        "\n",
        "        for file_name in tqdm(files_3):\n",
        "            self.labels.append(2)\n",
        "\n",
        "        for file_name in tqdm(files_4):\n",
        "            self.labels.append(3)\n",
        "\n",
        "        del files_1\n",
        "        del files_2\n",
        "        del files_3\n",
        "        del files_4\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image=cv2.imread(self.files_names[index])\n",
        "        #image = color_isolate(image.astype(np.float32))\n",
        "        y_label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)\n",
        "\n",
        "# Test Loader\n",
        "class BloodCell_test(Dataset):\n",
        "    def __init__(self, root,transform):\n",
        "        self.labels = []\n",
        "        self.dirName_1 = os.join(root,'/TEST/EOSINOPHIL') # path to test data with EOSINOPHILS cells\n",
        "        self.dirName_2 = os.join(root,'/TEST/LYMPHOCYTE') # path to test data with LYMPHOCYTES cells\n",
        "        self.dirName_3 = os.join(root,'/TEST/MONOCYTE') # path to test data with MONOCYTES cells\n",
        "        self.dirName_4 = os.join(root,'/TEST/NEUTROPHIL') # path to test data with NEUTROPHILS cellsself.files_names = []\n",
        "        self.files_names = []\n",
        "        self.transform = transform\n",
        "        self.load_images()\n",
        "        \n",
        "\n",
        "    def load_images(self):\n",
        "\n",
        "        # create list of paths to images\n",
        "        files_1 = [join(self.dirName_1, f) for f in listdir(self.dirName_1) if isfile(join(self.dirName_1, f))]\n",
        "        files_2 = [join(self.dirName_2, f) for f in listdir(self.dirName_2) if isfile(join(self.dirName_2, f))]\n",
        "        files_3 = [join(self.dirName_3, f) for f in listdir(self.dirName_3) if isfile(join(self.dirName_3, f))]\n",
        "        files_4 = [join(self.dirName_4, f) for f in listdir(self.dirName_4) if isfile(join(self.dirName_4, f))]\n",
        "        \n",
        "        # connect lists of different cells in one big list\n",
        "        self.files_names = files_1 + files_2 + files_3 + files_4\n",
        "\n",
        "        # creating label list\n",
        "        for file_name in tqdm(files_1):\n",
        "            self.labels.append(0)\n",
        "\n",
        "        for file_name in tqdm(files_2):\n",
        "            self.labels.append(1)\n",
        "\n",
        "        for file_name in tqdm(files_3):\n",
        "            self.labels.append(2)\n",
        "\n",
        "        for file_name in tqdm(files_4):\n",
        "            self.labels.append(3)\n",
        "\n",
        "        del files_1\n",
        "        del files_2\n",
        "        del files_3\n",
        "        del files_4\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image=cv2.imread(self.files_names[index])\n",
        "        #image = color_isolate(image.astype(np.float32))\n",
        "        y_label = self.labels[index]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image, y_label)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "J9W5bQwo5UlD",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# can be omitted if mean and std is already calculated\n",
        "# for calcualting mean and std od dataset\n",
        "def get_mean_and_std(dataloader):\n",
        "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
        "    for data, _ in tqdm(dataloader):\n",
        "        # Mean over batch, height and width, but not over the channels\n",
        "        channels_sum += torch.mean(data, dim=[0,2,3])\n",
        "        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])\n",
        "        num_batches += 1\n",
        "\n",
        "    mean = channels_sum / num_batches\n",
        "\n",
        "    # std = sqrt(E[X^2] - (E[X])^2)\n",
        "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
        "\n",
        "    return mean, std"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MrgL0wmx5Uk6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# model creation\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels, num_classes):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=9,\n",
        "            kernel_size=(11, 11),\n",
        "            stride=(1, 1),\n",
        "            padding=(1,1),\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=9,\n",
        "            out_channels=27,\n",
        "            kernel_size=(7, 7),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "        self.conv3 = nn.Conv2d(\n",
        "            in_channels=27,\n",
        "            out_channels=54,\n",
        "            kernel_size=(5, 5),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "        self.conv4 = nn.Conv2d(\n",
        "            in_channels=54,\n",
        "            out_channels=54,\n",
        "            kernel_size=(5, 5),\n",
        "            stride=(1, 1),\n",
        "            padding=(1,1),\n",
        "        )\n",
        "        self.conv5 = nn.Conv2d(\n",
        "            in_channels=54,\n",
        "            out_channels=108,\n",
        "            kernel_size=(5, 5),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "        self.conv6 = nn.Conv2d(\n",
        "            in_channels=108,\n",
        "            out_channels=108,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "        self.conv7 = nn.Conv2d(\n",
        "            in_channels=108,\n",
        "            out_channels=108,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "        self.conv8 = nn.Conv2d(\n",
        "            in_channels=108,\n",
        "            out_channels=108,\n",
        "            kernel_size=(3, 3),\n",
        "            stride=(1, 1),\n",
        "            padding=(0,0),\n",
        "        )\n",
        "\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=(5, 5), stride=(5, 5))\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
        "        self.drop1d = nn.Dropout(0.5)\n",
        "        self.BatchNorm2d1 = nn.BatchNorm2d(num_features=9)\n",
        "        self.BatchNorm2d3 = nn.BatchNorm2d(num_features=54)\n",
        "        self.fc1 = nn.Linear(41472, 5000)\n",
        "        self.fc2 = nn.Linear(5000, 5000)\n",
        "        self.fc3 = nn.Linear(5000, 5000)\n",
        "        self.fc4 = nn.Linear(5000, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.BatchNorm2d1(self.conv1(x)))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.BatchNorm2d3(self.conv3(x)))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.pool5(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.pool2(x)\n",
        "        x = F.relu(self.conv8(x))\n",
        "\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        #x = self.drop1d(x)\n",
        "        x = self.fc2(x)\n",
        "        #x = self.drop1d(x)\n",
        "        x = self.fc3(x)\n",
        "        #x = self.drop1d(x)\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AA56kxVRIL6P",
        "outputId": "f4864a1b-31cf-4464-b74e-423d215dc97e",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initial shape 320 240\n",
            "after 1st conv 312.0 232.0\n",
            "after 2nd conv 306.0 226.0\n",
            "after 3rd conv 302.0 222.0\n",
            "after 4th conv 300.0 220.0\n",
            "after 1st pooling 60.0 44.0\n",
            "after 5th conv 56.0 40.0\n",
            "after 6th conv 54.0 38.0\n",
            "after 7th conv 52.0 36.0\n",
            "after 2nd pooling 26.0 18.0\n",
            "after 8th conv 24.0 16.0\n",
            "Size of end output 41472.0\n"
          ]
        }
      ],
      "source": [
        "# calculate outputs shape of layers\n",
        "W=320\n",
        "H=240\n",
        "print('initial shape',W,H)\n",
        "#1st conv\n",
        "W=(W-11+2*1)/1+1\n",
        "H=(H-11+2*1)/1+1\n",
        "print('after 1st conv',W,H)\n",
        "# 2st conv\n",
        "W=(W-7+2*0)/1+1\n",
        "H=(H-7+2*0)/1+1\n",
        "print('after 2nd conv',W,H)\n",
        "# 3nd conv\n",
        "W=(W-5+2*0)/1+1\n",
        "H=(H-5+2*0)/1+1\n",
        "print('after 3rd conv',W,H)\n",
        "# 4nd conv#\n",
        "W=(W-5+2*1)/1+1\n",
        "H=(H-5+2*1)/1+1\n",
        "print('after 4th conv',W,H)\n",
        "# pool5\n",
        "W=W/5\n",
        "H=H/5\n",
        "print('after 1st pooling',W,H)\n",
        "# 5nd conv\n",
        "W=(W-5+2*0)/1+1\n",
        "H=(H-5+2*0)/1+1\n",
        "print('after 5th conv',W,H)\n",
        "# 6nd conv\n",
        "W=(W-3+2*0)/1+1\n",
        "H=(H-3+2*0)/1+1\n",
        "print('after 6th conv',W,H)\n",
        "# 7nd conv\n",
        "W=(W-3+2*0)/1+1\n",
        "H=(H-3+2*0)/1+1\n",
        "print('after 7th conv',W,H)\n",
        "# pool2\n",
        "W=W/2\n",
        "H=H/2\n",
        "print('after 2nd pooling',W,H)\n",
        "# 8nd conv\n",
        "W=(W-3+2*0)/1+1\n",
        "H=(H-3+2*0)/1+1\n",
        "print('after 8th conv',W,H)\n",
        "\n",
        "number_out_channels = 108\n",
        "print('Size of end output',H*W*number_out_channels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "8J5dzrruHsBe",
        "outputId": "9296df64-69b5-4f49-f01e-3867810b649b",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "using: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchrzanowski000\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.3"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220930_115246-3chgkhez</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/chrzanowski000/CNN_BloodCell_1/runs/3chgkhez\" target=\"_blank\">dainty-bee-66</a></strong> to <a href=\"https://wandb.ai/chrzanowski000/CNN_BloodCell_1\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2497/2497 [00:00<00:00, 1078263.88it/s]\n",
            "100%|██████████| 2483/2483 [00:00<00:00, 745647.37it/s]\n",
            "100%|██████████| 2478/2478 [00:00<00:00, 1408522.20it/s]\n",
            "100%|██████████| 2499/2499 [00:00<00:00, 677453.83it/s]\n",
            "100%|██████████| 623/623 [00:00<00:00, 225030.26it/s]\n",
            "100%|██████████| 620/620 [00:00<00:00, 228211.36it/s]\n",
            "100%|██████████| 620/620 [00:00<00:00, 239542.05it/s]\n",
            "100%|██████████| 624/624 [00:00<00:00, 267174.94it/s]\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'using: {device}')\n",
        "torch.backends.cudnn.benchmark = True #let cudnn chose most efficient way of calculating convulsions\n",
        "\n",
        "# Hyper-parameters\n",
        "in_channels = 3\n",
        "num_classes = 4\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "num_epochs = 100\n",
        "weight_decay = 0.001\n",
        "\n",
        "#Connenting to wandb project to log data there\n",
        "import wandb\n",
        "wandb.init(project=\"CNN_BloodCell_1\")\n",
        "\n",
        "# Initialize network\n",
        "model = CNN(in_channels=in_channels, num_classes=num_classes)\n",
        "model.to(device) \n",
        "\n",
        "# define transformations for datasets, stds and means have been calculated before with cell above on dataloaders without normalization\n",
        "transform_train = transforms.Compose([transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.6605, 0.6413, 0.6786],\n",
        "                                                           [0.2612, 0.2636, 0.2644])])\n",
        "transform_test = transforms.Compose([transforms.ToTensor(),\n",
        "                                     transforms.Normalize([0.6610, 0.6406, 0.6795],\n",
        "                                                          [0.2606, 0.2623, 0.2636])])\n",
        "\n",
        "#initialize datasets and dataloaders\n",
        "dataset_train = BloodCell_train(root='/notebooks/dataset2-master/dataset2-master/images', transform=transform_train)\n",
        "dataset_test = BloodCell_test(root='/notebooks/dataset2-master/dataset2-master/images', transform=transform_test)\n",
        "\n",
        "# set shuffle = True to randomize order\n",
        "# To avoid blocking computation code with data loading we set num_workers = 2\n",
        "# pin_memory = True will automatically put the fetched data Tensors in pinned memory, and thus enables faster data transfer to CUDA-enabled GPUs.\n",
        "train_loader = DataLoader(dataset=dataset_train, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=dataset_test, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60SNawqHevcG",
        "outputId": "d0382f95-2dbf-497e-e892-b8acae245ea5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of trained parameters in model: 257 980 958\n"
          ]
        }
      ],
      "source": [
        "mode_par_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(\"Number of trained parameters in model: \" + '{:,}'.format(mode_par_num).replace(',', ' '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qBZBXfxrjtXE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Check accuracy on training & test to see how good our model\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in tqdm(loader):\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DJ5CEXuZE2jG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "def save_model(test_acc):\n",
        "    dic_out = {'model_params': model.state_dict(), 'optimizer_params': optimizer.state_dict()}\n",
        "    df = pd.DataFrame.from_dict(dic_out)\n",
        "\n",
        "    # datetime object containing current date and time\n",
        "    now = datetime.now()\n",
        "    print(\"now =\", now)\n",
        "    dt_string = now.strftime(\"%d_%m_%Y__%H_%M_%S\")\n",
        "\n",
        "    # save model dict on Google drive with time signature\n",
        "    path = f'/content/drive/MyDrive/ML/CNN_BloodCell_{dt_string}_{test_acc}.csv'\n",
        "    df.to_csv(path, index = False, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sA7HZIVfBmWa",
        "outputId": "898dccca-827a-4283-802b-85b6b9a0fb9f",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch nr 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [03:00<00:00,  1.73it/s]\n",
            "100%|██████████| 312/312 [00:43<00:00,  7.13it/s]\n",
            "100%|██████████| 78/78 [00:16<00:00,  4.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 11:56:54.531343\n",
            "model saved: train_acc:38.45535659790039, test_acc:42.581424713134766\n",
            "Accuracy on training set: 38.46\n",
            "Accuracy on test set: 42.58\n",
            "epoch nr 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.77it/s]\n",
            "100%|██████████| 312/312 [01:06<00:00,  4.70it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:01:12.258122\n",
            "model saved: train_acc:51.411067962646484, test_acc:57.137115478515625\n",
            "Accuracy on training set: 51.41\n",
            "Accuracy on test set: 57.14\n",
            "epoch nr 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.77it/s]\n",
            "100%|██████████| 312/312 [00:59<00:00,  5.20it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:05:23.319711\n",
            "model saved: train_acc:66.37541198730469, test_acc:65.86248016357422\n",
            "Accuracy on training set: 66.38\n",
            "Accuracy on test set: 65.86\n",
            "epoch nr 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:55<00:00,  5.66it/s]\n",
            "100%|██████████| 78/78 [00:20<00:00,  3.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:09:35.137688\n",
            "model saved: train_acc:69.08706665039062, test_acc:66.3047866821289\n",
            "Accuracy on training set: 69.09\n",
            "Accuracy on test set: 66.30\n",
            "epoch nr 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [01:03<00:00,  4.91it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:13:42.145528\n",
            "model saved: train_acc:72.39128112792969, test_acc:70.88861846923828\n",
            "Accuracy on training set: 72.39\n",
            "Accuracy on test set: 70.89\n",
            "epoch nr 5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:01<00:00,  5.03it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:17:53.610692\n",
            "model saved: train_acc:75.715576171875, test_acc:73.86408996582031\n",
            "Accuracy on training set: 75.72\n",
            "Accuracy on test set: 73.86\n",
            "epoch nr 6\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:03<00:00,  4.94it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:22:06.492310\n",
            "model saved: train_acc:82.89645385742188, test_acc:79.05106353759766\n",
            "Accuracy on training set: 82.90\n",
            "Accuracy on test set: 79.05\n",
            "epoch nr 7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:56<00:00,  5.52it/s]\n",
            "100%|██████████| 78/78 [00:20<00:00,  3.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 81.32\n",
            "Accuracy on test set: 78.05\n",
            "epoch nr 8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:59<00:00,  5.25it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:30:23.399001\n",
            "model saved: train_acc:82.31394958496094, test_acc:82.46883392333984\n",
            "Accuracy on training set: 82.31\n",
            "Accuracy on test set: 82.47\n",
            "epoch nr 9\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:57<00:00,  5.38it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.58it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 81.46\n",
            "Accuracy on test set: 77.52\n",
            "epoch nr 10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:57<00:00,  5.38it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.69it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:38:38.480018\n",
            "model saved: train_acc:88.2695541381836, test_acc:85.20305633544922\n",
            "Accuracy on training set: 88.27\n",
            "Accuracy on test set: 85.20\n",
            "epoch nr 11\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:52<00:00,  5.91it/s]\n",
            "100%|██████████| 78/78 [00:19<00:00,  3.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:42:46.796529\n",
            "model saved: train_acc:92.88941955566406, test_acc:87.45476531982422\n",
            "Accuracy on training set: 92.89\n",
            "Accuracy on test set: 87.45\n",
            "epoch nr 12\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:59<00:00,  5.22it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:46:49.964839\n",
            "model saved: train_acc:95.16922760009766, test_acc:87.97747802734375\n",
            "Accuracy on training set: 95.17\n",
            "Accuracy on test set: 87.98\n",
            "epoch nr 13\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:00<00:00,  5.15it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 94.46\n",
            "Accuracy on test set: 87.25\n",
            "epoch nr 14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:01<00:00,  5.10it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 96.90\n",
            "Accuracy on test set: 87.29\n",
            "epoch nr 15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:54<00:00,  5.73it/s]\n",
            "100%|██████████| 78/78 [00:19<00:00,  3.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "now = 2022-09-30 12:59:19.345206\n",
            "model saved: train_acc:96.25389099121094, test_acc:88.41978454589844\n",
            "Accuracy on training set: 96.25\n",
            "Accuracy on test set: 88.42\n",
            "epoch nr 16\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:56<00:00,  5.51it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 97.68\n",
            "Accuracy on test set: 86.65\n",
            "epoch nr 17\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:58<00:00,  5.32it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 97.83\n",
            "Accuracy on test set: 85.52\n",
            "epoch nr 18\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:54<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:58<00:00,  5.35it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 91.79\n",
            "Accuracy on test set: 82.35\n",
            "epoch nr 19\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:53<00:00,  5.86it/s]\n",
            "100%|██████████| 78/78 [00:19<00:00,  4.07it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 97.30\n",
            "Accuracy on test set: 85.61\n",
            "epoch nr 20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:59<00:00,  5.20it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 98.74\n",
            "Accuracy on test set: 86.81\n",
            "epoch nr 21\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:59<00:00,  5.21it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 98.54\n",
            "Accuracy on test set: 87.13\n",
            "epoch nr 22\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:01<00:00,  5.07it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 97.98\n",
            "Accuracy on test set: 86.17\n",
            "epoch nr 23\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:54<00:00,  5.76it/s]\n",
            "100%|██████████| 78/78 [00:15<00:00,  4.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 98.25\n",
            "Accuracy on test set: 86.93\n",
            "epoch nr 24\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:56<00:00,  5.50it/s]\n",
            "100%|██████████| 78/78 [00:09<00:00,  7.99it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 99.34\n",
            "Accuracy on test set: 86.29\n",
            "epoch nr 25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:56<00:00,  5.48it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 69.96\n",
            "Accuracy on test set: 68.11\n",
            "epoch nr 26\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:54<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:57<00:00,  5.40it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 84.26\n",
            "Accuracy on test set: 75.71\n",
            "epoch nr 27\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:52<00:00,  5.93it/s]\n",
            "100%|██████████| 78/78 [00:19<00:00,  4.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 93.43\n",
            "Accuracy on test set: 83.39\n",
            "epoch nr 28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [01:00<00:00,  5.15it/s]\n",
            "100%|██████████| 78/78 [00:12<00:00,  6.09it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 96.77\n",
            "Accuracy on test set: 83.59\n",
            "epoch nr 29\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:00<00:00,  5.17it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 98.88\n",
            "Accuracy on test set: 85.89\n",
            "epoch nr 30\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [01:00<00:00,  5.16it/s]\n",
            "100%|██████████| 78/78 [00:13<00:00,  5.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 99.52\n",
            "Accuracy on test set: 86.37\n",
            "epoch nr 31\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:55<00:00,  1.78it/s]\n",
            "100%|██████████| 312/312 [00:54<00:00,  5.69it/s]\n",
            "100%|██████████| 78/78 [00:19<00:00,  3.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 99.15\n",
            "Accuracy on test set: 87.21\n",
            "epoch nr 32\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 312/312 [02:49<00:00,  1.84it/s]\n",
            "100%|██████████| 312/312 [00:57<00:00,  5.39it/s]\n",
            "100%|██████████| 78/78 [00:14<00:00,  5.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on training set: 99.13\n",
            "Accuracy on test set: 85.40\n",
            "epoch nr 33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  3%|▎         | 9/312 [00:05<03:03,  1.65it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ef80964fde28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Get data to device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "start_time = time.time()\n",
        "# Optional\n",
        "wandb.watch(model, criterion, log=\"all\", log_freq=400)\n",
        "train_acc_best = 0\n",
        "test_acc_best = 0\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'epoch nr {epoch}')\n",
        "    for data, targets in tqdm(train_loader):\n",
        "        # Get data to device\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "\n",
        "        # setting parameteres gradients to None, takes less memory than setting to '0'\n",
        "        for param in model.parameters():\n",
        "            param.grad = None\n",
        "\n",
        "        # forward and loss calculation\n",
        "        scores=model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "        # log loss to wandb\n",
        "        wandb.log({\"loss\": loss})\n",
        "\n",
        "        # backward\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "    \n",
        "    # Calculate Accuracy and save model if test acc increased\n",
        "    train_acc = check_accuracy(train_loader, model)*100\n",
        "    test_acc = check_accuracy(test_loader, model)*100\n",
        "    if test_acc > test_acc_best:\n",
        "        save_model(test_acc)\n",
        "        test_acc_best = test_acc\n",
        "        train_acc_best = train_acc\n",
        "        print(f'model saved: train_acc:{train_acc_best}, test_acc:{test_acc_best}')\n",
        "\n",
        "    # log train_acc and test_acc to wandb\n",
        "    wandb.log({\"train_acc\": train_acc})\n",
        "    wandb.log({\"test_acc\": test_acc})\n",
        "    print(f\"Accuracy on training set: {train_acc:.2f}\")    \n",
        "    print(f\"Accuracy on test set: {test_acc:.2f}\")\n",
        "\n",
        "    #print('cached CUDA memory: ',torch.cuda.memory_cached())\n",
        "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "torch.cuda.empty_cache()\n",
        "print(f\"Highest accuracy on training set: {train_acc_best}\")\n",
        "print(f\"Highest accuracy on test set: {test_acc_best}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "a9dc89d7e7574d154d845016cb28e163d7de30868d1de894c627855ae4c7cc3b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
